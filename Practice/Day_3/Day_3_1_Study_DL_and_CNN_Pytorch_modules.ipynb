{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jm-_H-aDcJPV"
      },
      "source": [
        "# Day_3_1 Study CNN Pytorch modules\n",
        "- Deep Learning과 Convolution Neural Network과 관련한 Pytorch modules에 대해 실습"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mGM_7D2Pv26U"
      },
      "source": [
        "![image.png](http://drive.google.com/uc?id=1xSFMz26Z14rldETZG4nXDPq_ZZKK2ISF)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=13WyqK4RTceUmGKL6_Iwgz_2sShX2pVGC)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=1eBPt8_ZfJrG-PrYMffXb_DpaPRutK9jh)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=1PsSApUabTfSseQMH2vLyZKtx9fMJ6fA1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ClTdLPkKgvsS"
      },
      "source": [
        "## 1) nn.Conv2d\n",
        "- 2-dim 데이터에 하나의 Convolution layer를 생성\n",
        "- 필요한 하이퍼파라미터를 설정하면 Convolution layer에 필요한 parameter weight를 자동으로 선언\n",
        "- `Conv2d(in_channels, out_channels, kernel_size, stride=1, padding=0, dilation=1, groups=1, bias=True, padding_mode='zeros')`\n",
        "### parameters\n",
        "  - in_channels: 입력 채널 수. 흑백 이미지일 경우 1, RGB 값을 가진 이미지일 경우 3\n",
        "  - out_channels: 출력 채널 수\n",
        "  - kernel_size: 커널 사이즈\n",
        "  - stride: stride 사이즈\n",
        "  - padding: padding 사이즈\n",
        "### shape\n",
        "1. Input tensor($N, C_{in}, H_{in}, W_{in}$)\n",
        " - $N$: batch의 크기\n",
        " - $C_{in}$ : `in_channerls`에 넣은 값과 일치해야 함.\n",
        " - $H_{in}$ : 2D input tensor의 높이\n",
        " - $ W_{in}$:  2D input tensor의 너비\n",
        "\n",
        "\n",
        "- [doc] (https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=18ZaNZcwh4SOBSa8WmXtGgQM4iDi6q6F5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HdGyn7qivFhs"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z5xHGN9iUKp"
      },
      "source": [
        "### Example 1) kernel_size=3, stride=1, padding=0\n",
        "![image.png](http://drive.google.com/uc?id=1dvnKVDptCOD1VLtiiTztOB2Lp4SAkuOE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M6Z5_4kBvF-m",
        "outputId": "d6b5a770-a8c9-4760-c01d-5259cb70e4c0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "input = torch.ones(1,1,4,4)\n",
        "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=1, padding=0)\n",
        "output = conv_layer(input)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WH69ollWmPTv"
      },
      "source": [
        "### Example 2) kernel_size=3, stride=2, padding=0\n",
        "![image.png](http://drive.google.com/uc?id=1SgTHZ4mGkQgaHmpVNi-IcHqP1pW5Crm0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aagJ40kTvHCW",
        "outputId": "db62ad98-6c2d-4174-c31e-5c807267bcea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "input = torch.ones(1,1,5,5)\n",
        "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=3, stride=2, padding=0)\n",
        "output = conv_layer(input)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ojKOdUH9mPbj"
      },
      "source": [
        "### Example 3) kernel_size=4, stride=1, padding=2\n",
        "![image.png](http://drive.google.com/uc?id=1jA5h5lM6mbMtRtBT8rRFacf6yQazmHzW)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XFf37HKxvP54",
        "outputId": "af3e1a57-5231-4607-a141-60667f4b0a67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 6, 6])\n"
          ]
        }
      ],
      "source": [
        "input = torch.ones(1,1,5,5)\n",
        "conv_layer = nn.Conv2d(in_channels=1, out_channels=1, kernel_size=4, stride=1, padding=2)\n",
        "output = conv_layer(input)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhM7g6qqmPiU"
      },
      "source": [
        "### Excercise 1) kernel_size=?, stride=?, padding=?\n",
        "![image.png](http://drive.google.com/uc?id=1uAgXHskAXGtdowxGKw99Dtw4n4f_X34s)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "81nhcGmivU_f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "122442a2-35c8-4e46-832b-a9385f099a7d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "input = torch.ones(1,1,6,6)\n",
        "########################################## Complete This Code~!\n",
        "in_channels=None\n",
        "out_channels=None\n",
        "kernel_size=None\n",
        "stride=None\n",
        "padding=None\n",
        "conv_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "########################################## Complete This Code~!\n",
        "output = conv_layer(input)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GoDsxDyLmPm1"
      },
      "source": [
        "### Excercise 2) kernel_size=?, stride=?, padding=?\n",
        "![image.png](http://drive.google.com/uc?id=1Q2WLIYER2T5h8Pri9diRs3J_Kmjb7MXo)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQDSRygVvbbO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a7cf5a11-cb53-4e3b-fb7d-5c09e833c006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 5, 5])\n"
          ]
        }
      ],
      "source": [
        "input = torch.ones(1,1,5,5)\n",
        "########################################## Complete This Code~!\n",
        "in_channels=None\n",
        "out_channels=None\n",
        "kernel_size=None\n",
        "stride=None\n",
        "padding=None\n",
        "conv_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "########################################## Complete This Code~!\n",
        "output = conv_layer(input)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1sBLs9zvmPrb"
      },
      "source": [
        "### Excercise 3) kernel_size=?, stride=?, padding=?\n",
        "![image.png](http://drive.google.com/uc?id=15MRDXon_68pySZHQy9wBqdbwp8HQNdv8)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MMoLbYxvmhH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "823ad912-20c0-4693-d263-029163e40e01"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "input = torch.ones(1,1,5,5)\n",
        "########################################## Complete This Code~!\n",
        "in_channels=None\n",
        "out_channels=None\n",
        "kernel_size=None\n",
        "stride=None\n",
        "padding=None\n",
        "conv_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "########################################## Complete This Code~!\n",
        "output = conv_layer(input)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VcLx4RdLmPyj"
      },
      "source": [
        "### Excercise 4) kernel_size=?, stride=?, padding=?\n",
        "![image.png](http://drive.google.com/uc?id=17yCuQSaW2Q0XUwwHG8tBvts15Y-U3we1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rjoq0NZ2vsTX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b73cf66-e171-439b-94fa-b7ef5b2ee0bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 7, 7])\n"
          ]
        }
      ],
      "source": [
        "input = torch.ones(1,1,5,5)\n",
        "########################################## Complete This Code~!\n",
        "in_channels=None\n",
        "out_channels=None\n",
        "kernel_size=None\n",
        "stride=None\n",
        "padding=None\n",
        "conv_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "########################################## Complete This Code~!\n",
        "output = conv_layer(input)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jX23Ob3_wqvA"
      },
      "source": [
        "### Excercise 5) kernel_size=?, stride=?, padding=?\n",
        "![image.png](http://drive.google.com/uc?id=1fNZTyHOtHX0y7sFW-e6tx0qP8mrQ7wK8)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q8-EEdMyw9wX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6fa23890-43b1-4850-861d-e3f1ceaee5e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 2, 3, 3])\n"
          ]
        }
      ],
      "source": [
        "input = torch.ones(1,3,5,5)\n",
        "########################################## Complete This Code~!\n",
        "in_channels=None\n",
        "out_channels=None\n",
        "kernel_size=None\n",
        "stride=None\n",
        "padding=None\n",
        "conv_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "########################################## Complete This Code~!\n",
        "output = conv_layer(input)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IH0meoGQyuLA"
      },
      "source": [
        "### Excercise 6) Input size=(7,7), kernel_size=3, stride=2, padding=0, Output size=?\n",
        "![image.png](http://drive.google.com/uc?id=1d9C1FkXHRwx86OfBZ2-1XrIVyak_skMG)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aos7P8uayt2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "671f46ab-d1a9-48d0-fcd2-5227dd84543a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 2, 2])\n"
          ]
        }
      ],
      "source": [
        "input = torch.ones(1,1,6,6)\n",
        "########################################## Complete This Code~!\n",
        "in_channels=None\n",
        "out_channels=None\n",
        "kernel_size=None\n",
        "stride=None\n",
        "padding=None\n",
        "conv_layer = nn.Conv2d(in_channels=in_channels, out_channels=out_channels, kernel_size=kernel_size, stride=stride, padding=padding)\n",
        "########################################## Complete This Code~!\n",
        "output = conv_layer(input)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NRN2Lz0cdqD8"
      },
      "source": [
        "## < Convolution output feature map size 계산 >\n",
        "![image.png](http://drive.google.com/uc?id=12reHf9xtapZrVBG4LlNbNGa37ZeFfUqk)\n",
        "![image.png](http://drive.google.com/uc?id=1iqd-9-hHgnc6Zz7kR6v9EMhLWrMmY07N)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-w3DKShN0dmP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a92ec3e8-8fdd-48af-a1df-d48c22ba7d51"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "예제 1 정답 : 55\n",
            "예제 2 정답 : 29\n",
            "예제 3 정답 : 32\n",
            "예제 4 정답 : (28, 60)\n",
            "예제 5 정답 : (64, 32)\n"
          ]
        }
      ],
      "source": [
        "# 예제 1)\n",
        "########################################## Complete This Code~!\n",
        "ans_1 = int( (227 - 11 + 2*0) / 4 + 1 )\n",
        "########################################## Complete This Code~!\n",
        "print(f'예제 1 정답 : {ans_1}')\n",
        "\n",
        "# 예제 2)\n",
        "ans_2 = int( (64 - 7 + 2*0) / 2 + 1 )\n",
        "print(f'예제 2 정답 : {ans_2}') # 28.5 + 1 => 29\n",
        "\n",
        "# 예제 3)\n",
        "########################################## Complete This Code~!\n",
        "ans_3 = int( (32 - 5 + 2*2) / 1 + 1 )\n",
        "########################################## Complete This Code~!\n",
        "print(f'예제 3 정답 : {ans_3}')\n",
        "\n",
        "# 예제 4)\n",
        "# <Height>\n",
        "ans_4_height = int( (32 - 5 + 2*0) / 1 + 1 )\n",
        "# <Width>\n",
        "ans_4_width = int( (64 - 5 + 2*0) / 1 + 1 )\n",
        "print(f'예제 4 정답 : ({ans_4_height}, {ans_4_width})') # (28, 60)\n",
        "\n",
        "# 예제 5)\n",
        "# <Height>\n",
        "########################################## Complete This Code~!\n",
        "ans_5_height = int((64 - 3 + 2 * 1) + 1)\n",
        "########################################## Complete This Code~!\n",
        "#<Width>\n",
        "########################################## Complete This Code~!\n",
        "ans_5_width = int((32 - 3 + 2 * 1) + 1)\n",
        "########################################## Complete This Code~!\n",
        "print(f'예제 5 정답 : ({ans_5_height}, {ans_5_width})')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yUqcnjUX2cnZ",
        "outputId": "ded26e9b-9f87-4c5e-c985-81dfa20035ca"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 55, 55])\n"
          ]
        }
      ],
      "source": [
        "# 각 예제에 맞게 INPUT 값을 바꾸어 설정할 수 있습니다.\n",
        "INPUT_SIZE = (227,227)\n",
        "IN_CHANNELS = 3\n",
        "OUT_CHANNELS = 10\n",
        "KERNEL_SIZE = 11\n",
        "STRIDE = 4\n",
        "PADDING = 0\n",
        "\n",
        "input = torch.ones(1,IN_CHANNELS,INPUT_SIZE[0],INPUT_SIZE[1])\n",
        "func = nn.Conv2d(in_channels=IN_CHANNELS, out_channels=OUT_CHANNELS, kernel_size=KERNEL_SIZE, stride=STRIDE, padding=PADDING)\n",
        "output = func(input)\n",
        "print(output.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MpZpQmjk1mYk"
      },
      "source": [
        "## 2) nn.MaxPool2d\n",
        "\n",
        "- Patch 내에서 가장 두드러진 feature를 추출.\n",
        "- 모델이 중요한 feature에만 집중할 수 있도록 함. (나머지는 무시)\n",
        "\n",
        "- [doc] (https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=1010fN_7lMHuxmda3_gdSxfbW36yTC6F5)\n",
        "![image.png](http://drive.google.com/uc?id=1D2e9iFzJZMPLxRYucC4LS2B44-a3dlQk)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=1xEmoXL-lmanXO6eSYDEmq7_cyFB73dRF)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVg1KI146VxQ",
        "outputId": "d838ad35-4a3f-4186-9775-9ff6aed22f87"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 0., 2., 3.],\n",
            "         [4., 6., 6., 8.],\n",
            "         [3., 1., 1., 0.],\n",
            "         [1., 2., 2., 4.]]])\n"
          ]
        }
      ],
      "source": [
        "input = torch.tensor([[[1.,0.,2.,3.],[4.,6.,6.,8.],[3.,1.,1.,0.],[1.,2.,2.,4.]]])\n",
        "print(input)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "func = nn.MaxPool2d(kernel_size=2)\n",
        "output = func(input)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mtpDpEek1yJ",
        "outputId": "b5376440-04f4-4687-ee86-b23c87c99689"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[6., 8.],\n",
            "         [3., 4.]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SXJ3Ix0cxREJ"
      },
      "source": [
        "## 3) nn.AvgPool2d\n",
        "\n",
        "- Patch 내의 feature들을 균형있게(balanced) 추출하는 방식\n",
        "- 정보 손실이 적어 detail을 놓치지 않을 수 있음 (중요하거나/하지 않거나 하는 정보를 구별하지 못하게 됨)\n",
        "\n",
        "\n",
        "- [doc] (https://pytorch.org/docs/stable/generated/torch.nn.AvgPool2d.html)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=1z4OjHBduieJQVJqquISgrsmVqlVlfgS1)\n",
        "![image.png](http://drive.google.com/uc?id=10U4Z4OGKSWQHeDMa-f9KRnUXhfGKhKnk)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=1wg2vJ8t780P6l5EUw1oLF3QTSjZBse0a)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4SBl9g3A3uM",
        "outputId": "71ab5b0c-372f-4a54-b1ea-8894509962b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 0., 2., 3.],\n",
            "         [4., 6., 6., 8.],\n",
            "         [3., 1., 1., 0.],\n",
            "         [1., 2., 2., 4.]]])\n"
          ]
        }
      ],
      "source": [
        "input = torch.tensor([[[1.,0.,2.,3.],[4.,6.,6.,8.],[3.,1.,1.,0.],[1.,2.,2.,4.]]])\n",
        "print(input)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "func = nn.AvgPool2d(kernel_size=4)\n",
        "output = func(input)\n",
        "print(output)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4klI2XAylFP7",
        "outputId": "9c539f7f-5ca4-48c8-b9bc-34f2e0ca9fd2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[2.7500]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4KnKLq_H58kw"
      },
      "source": [
        "## 4) nn.AdaptiveAvgPool2d()\n",
        "- kernel_size, stride, padding을 입력하는 대신에 output의 사이즈를 입력\n",
        "-  위의 식에 따라서 자동으로 kernel_size, stride, padding이 결정되어 pooling을 할 수 있음.\n",
        "- 즉, Average Pooling을 할 때, 출력 크기 조절하기가 상당히 쉬워짐\n",
        "\n",
        "- [doc] (https://pytorch.org/docs/stable/generated/torch.nn.AdaptiveAvgPool2d.html)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=190yR-M7yTb6ZlILOi4J5RSrfLeh_iul8)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=1KMgjceD4tsS67kUvAb1BYC29HXWJb0Hr)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrqjmhhSA7yn",
        "outputId": "3abfc43a-d808-4c0c-be99-f2976f60734d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[1., 0., 2., 3.],\n",
            "         [4., 6., 6., 8.],\n",
            "         [3., 1., 1., 0.],\n",
            "         [1., 2., 2., 4.]]])\n"
          ]
        }
      ],
      "source": [
        "input = torch.tensor([[[1.,0.,2.,3.],[4.,6.,6.,8.],[3.,1.,1.,0.],[1.,2.,2.,4.]]]) # shpae : [1,4,4]\n",
        "print(input)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "func = nn.AdaptiveAvgPool2d(1) # (1, 1)\n",
        "output = func(input)\n",
        "print(output) # shape : [1,1,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cAHQ31iqljQu",
        "outputId": "eefb15dd-b1d6-4625-c95b-4097f1342342"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[2.7500]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "func = nn.AdaptiveAvgPool2d(2) # (2, 2)\n",
        "output = func(input)\n",
        "print(output) # shape : [1,2,2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2GrtZCqqPpPz",
        "outputId": "351fe202-55c8-4469-b942-00cd658982ae"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[2.7500, 4.7500],\n",
            "         [1.7500, 1.7500]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iRdf0cDhdBf1",
        "outputId": "03fa5810-2228-4a99-9012-472e410fc1e1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[ 0.7883, -0.9139, -2.3117,  0.5276],\n",
            "          [ 0.8452, -2.9044,  1.2648,  1.5481],\n",
            "          [-0.5473, -0.2154,  0.4562,  0.8117],\n",
            "          [-0.6663, -1.1137, -0.5429,  1.2258]],\n",
            "\n",
            "         [[-0.3522, -0.2055, -0.5270, -0.2399],\n",
            "          [ 0.8420,  0.1785, -0.2320,  1.0298],\n",
            "          [-1.0613,  0.8084,  1.1157, -0.5487],\n",
            "          [-0.4375,  0.1039, -1.6958, -0.6947]],\n",
            "\n",
            "         [[ 0.2658,  0.0365, -0.4793, -0.6779],\n",
            "          [ 0.3146,  1.1199, -0.6147, -0.9724],\n",
            "          [ 0.7409, -0.2682, -1.3775, -1.3753],\n",
            "          [-2.8159,  0.3868,  0.6530, -0.5435]]]])\n"
          ]
        }
      ],
      "source": [
        "# input channel = 3인 경우\n",
        "input = torch.randn((1,3,4,4))\n",
        "print(input)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "func = nn.AdaptiveAvgPool2d(1)\n",
        "output = func(input)\n",
        "print(output) # shape : [1,3,1,1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eflFZt9ql10F",
        "outputId": "dac51a63-37ba-4c68-fd70-011e97344e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-0.1092]],\n",
            "\n",
            "         [[-0.1198]],\n",
            "\n",
            "         [[-0.3505]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R7JRuJhBOzz",
        "outputId": "8c16459e-4ac5-420a-830c-61c64e4395e3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-0.2497]],\n",
            "\n",
            "         [[ 0.6585]],\n",
            "\n",
            "         [[-1.3173]]]])\n"
          ]
        }
      ],
      "source": [
        "input = torch.randn((1,3,1,1))\n",
        "print(input)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# input size보다 output size가 더 큰 경우\n",
        "\n",
        "func = nn.AdaptiveAvgPool2d(7) # (7, 7)\n",
        "output = func(input)\n",
        "print(output) # shape : [1,3,7,7]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWSg0MM3mEZr",
        "outputId": "9356d0f6-d4fd-465d-aac5-addd83a059de"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[[[-0.2497, -0.2497, -0.2497, -0.2497, -0.2497, -0.2497, -0.2497],\n",
            "          [-0.2497, -0.2497, -0.2497, -0.2497, -0.2497, -0.2497, -0.2497],\n",
            "          [-0.2497, -0.2497, -0.2497, -0.2497, -0.2497, -0.2497, -0.2497],\n",
            "          [-0.2497, -0.2497, -0.2497, -0.2497, -0.2497, -0.2497, -0.2497],\n",
            "          [-0.2497, -0.2497, -0.2497, -0.2497, -0.2497, -0.2497, -0.2497],\n",
            "          [-0.2497, -0.2497, -0.2497, -0.2497, -0.2497, -0.2497, -0.2497],\n",
            "          [-0.2497, -0.2497, -0.2497, -0.2497, -0.2497, -0.2497, -0.2497]],\n",
            "\n",
            "         [[ 0.6585,  0.6585,  0.6585,  0.6585,  0.6585,  0.6585,  0.6585],\n",
            "          [ 0.6585,  0.6585,  0.6585,  0.6585,  0.6585,  0.6585,  0.6585],\n",
            "          [ 0.6585,  0.6585,  0.6585,  0.6585,  0.6585,  0.6585,  0.6585],\n",
            "          [ 0.6585,  0.6585,  0.6585,  0.6585,  0.6585,  0.6585,  0.6585],\n",
            "          [ 0.6585,  0.6585,  0.6585,  0.6585,  0.6585,  0.6585,  0.6585],\n",
            "          [ 0.6585,  0.6585,  0.6585,  0.6585,  0.6585,  0.6585,  0.6585],\n",
            "          [ 0.6585,  0.6585,  0.6585,  0.6585,  0.6585,  0.6585,  0.6585]],\n",
            "\n",
            "         [[-1.3173, -1.3173, -1.3173, -1.3173, -1.3173, -1.3173, -1.3173],\n",
            "          [-1.3173, -1.3173, -1.3173, -1.3173, -1.3173, -1.3173, -1.3173],\n",
            "          [-1.3173, -1.3173, -1.3173, -1.3173, -1.3173, -1.3173, -1.3173],\n",
            "          [-1.3173, -1.3173, -1.3173, -1.3173, -1.3173, -1.3173, -1.3173],\n",
            "          [-1.3173, -1.3173, -1.3173, -1.3173, -1.3173, -1.3173, -1.3173],\n",
            "          [-1.3173, -1.3173, -1.3173, -1.3173, -1.3173, -1.3173, -1.3173],\n",
            "          [-1.3173, -1.3173, -1.3173, -1.3173, -1.3173, -1.3173, -1.3173]]]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YmA_jD5_QEkY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}