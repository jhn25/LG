{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D9UUcbMe5uHd"
      },
      "source": [
        "# Day3-3 : VGG, RESNET model simple Implementation with CIFAR10 dataset\n",
        "#### 이번 실습에서는 CNN 아키텍쳐 중 가장 대표적인 VGG과 RESNET 모델을 간단히 구현해보고 CIFAR-10 데이터셋에 대해 학습 및 Inference를 해볼 계획입니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pMY3CPV4ebV2"
      },
      "source": [
        "## Example 1) VGG16 모델 구현\n",
        "- [doc] (https://arxiv.org/pdf/1409.1556.pdf)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=1E6MVIcFCsImwWQGOhC-8KUQqAe2W_I28)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=1jT9jhqMzEaHoma5xvro5jf6PFOq7FlLJ)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=17DgT11woHwXACEGOfvkVd8pYmxRI7vQl)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jbce4wfMMTqv",
        "outputId": "e28a6f7d-72fd-448c-8e45-155e3188bec5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets, utils\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# DEVICE 설정\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "\n",
        "# Parameter 설정\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "LR = 0.0001\n",
        "\n",
        "# Transform 설정\n",
        "transform_CIFAR10 = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "# Dataset 설정\n",
        "train_dataset = datasets.CIFAR10(root = '../data',\n",
        "                                         train = True,\n",
        "                                         download = True,\n",
        "                                         transform = transform_CIFAR10)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root = '../data',\n",
        "                                train = False,\n",
        "                                download = True,\n",
        "                                transform = transform_CIFAR10)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = BATCH_SIZE,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHuz4grSH-lZ",
        "outputId": "e19dcc61-b403-49e4-a35a-16ecbe702357"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([3, 224, 224])"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_dataset[0][0].size()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_JeDJmfNuN0k",
        "outputId": "f378edc8-0e01-4f72-8a23-786ad195d22a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "              ReLU-2         [-1, 64, 224, 224]               0\n",
            "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
            "              ReLU-4         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
            "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
            "              ReLU-7        [-1, 128, 112, 112]               0\n",
            "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
            "              ReLU-9        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
            "             ReLU-12          [-1, 256, 56, 56]               0\n",
            "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-14          [-1, 256, 56, 56]               0\n",
            "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-16          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
            "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
            "             ReLU-19          [-1, 512, 28, 28]               0\n",
            "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-21          [-1, 512, 28, 28]               0\n",
            "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-23          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
            "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-26          [-1, 512, 14, 14]               0\n",
            "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-28          [-1, 512, 14, 14]               0\n",
            "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-30          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
            "           Linear-32                 [-1, 4096]     102,764,544\n",
            "             ReLU-33                 [-1, 4096]               0\n",
            "          Dropout-34                 [-1, 4096]               0\n",
            "           Linear-35                 [-1, 4096]      16,781,312\n",
            "             ReLU-36                 [-1, 4096]               0\n",
            "          Dropout-37                 [-1, 4096]               0\n",
            "           Linear-38                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 134,301,514\n",
            "Trainable params: 134,301,514\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 218.58\n",
            "Params size (MB): 512.32\n",
            "Estimated Total Size (MB): 731.48\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "# Model 구현\n",
        "class Custom_VGG(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Custom_VGG, self).__init__()\n",
        "        ########################################## Complete This Code~!\n",
        "        self.maxpool2d = nn.MaxPool2d(kernel_size=2)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.dropout = nn.Dropout()\n",
        "\n",
        "        self.conv1_1 = nn.Conv2d(3,64,3,padding=1)\n",
        "        self.conv1_2 = nn.Conv2d(64,64,3,padding=1)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(64,128,3,padding=1)\n",
        "        self.conv2_2 = nn.Conv2d(128,128,3,padding=1)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(128,256,3,padding=1)\n",
        "        self.conv3_2 = nn.Conv2d(256,256,3,padding=1)\n",
        "        self.conv3_3 = nn.Conv2d(256,256,3,padding=1)\n",
        "\n",
        "        self.conv4_1 = nn.Conv2d(256,512,3,padding=1)\n",
        "        self.conv4_2 = nn.Conv2d(512,512,3,padding=1)\n",
        "        self.conv4_3 = nn.Conv2d(512,512,3,padding=1)\n",
        "\n",
        "        self.conv5_1 = nn.Conv2d(512,512,3,padding=1)\n",
        "        self.conv5_2 = nn.Conv2d(512,512,3,padding=1)\n",
        "        self.conv5_3 = nn.Conv2d(512,512,3,padding=1)\n",
        "\n",
        "        self.fc1 = nn.Linear(512*7*7, 4096)\n",
        "        self.fc2 = nn.Linear(4096, 4096)\n",
        "        self.fc3 = nn.Linear(4096, 10)\n",
        "        ########################################## Complete This Code~!\n",
        "\n",
        "    def forward(self, x): #(bs,3,224,224)\n",
        "        ########################################## Complete This Code~!\n",
        "        x = self.relu(self.conv1_1(x))\n",
        "        x = self.relu(self.conv1_2(x))\n",
        "        x = self.maxpool2d(x)\n",
        "\n",
        "        x = self.relu(self.conv2_1(x))\n",
        "        x = self.relu(self.conv2_2(x))\n",
        "        x = self.maxpool2d(x)\n",
        "\n",
        "        x = self.relu(self.conv3_1(x))\n",
        "        x = self.relu(self.conv3_2(x))\n",
        "        x = self.relu(self.conv3_3(x))\n",
        "        x = self.maxpool2d(x)\n",
        "\n",
        "        x = self.relu(self.conv4_1(x))\n",
        "        x = self.relu(self.conv4_2(x))\n",
        "        x = self.relu(self.conv4_3(x))\n",
        "        x = self.maxpool2d(x)\n",
        "\n",
        "        x = self.relu(self.conv5_1(x))\n",
        "        x = self.relu(self.conv5_2(x))\n",
        "        x = self.relu(self.conv5_3(x))\n",
        "        x = self.maxpool2d(x) #(bs,512,7,7)\n",
        "\n",
        "        x = x.view(-1,512*7*7) # Flatten\n",
        "\n",
        "        x = self.dropout(self.relu(self.fc1(x)))\n",
        "        x = self.dropout(self.relu(self.fc2(x)))\n",
        "        x = self.fc3(x)\n",
        "        ########################################## Complete This Code~!\n",
        "        return x\n",
        "model = Custom_VGG().to(DEVICE)\n",
        "summary(model, (3,224,224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jkqHEqDBaoPQ",
        "outputId": "2ca52501-173c-41df-92e9-04173ca5d6c0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1         [-1, 64, 224, 224]           1,792\n",
            "              ReLU-2         [-1, 64, 224, 224]               0\n",
            "            Conv2d-3         [-1, 64, 224, 224]          36,928\n",
            "              ReLU-4         [-1, 64, 224, 224]               0\n",
            "         MaxPool2d-5         [-1, 64, 112, 112]               0\n",
            "            Conv2d-6        [-1, 128, 112, 112]          73,856\n",
            "              ReLU-7        [-1, 128, 112, 112]               0\n",
            "            Conv2d-8        [-1, 128, 112, 112]         147,584\n",
            "              ReLU-9        [-1, 128, 112, 112]               0\n",
            "        MaxPool2d-10          [-1, 128, 56, 56]               0\n",
            "           Conv2d-11          [-1, 256, 56, 56]         295,168\n",
            "             ReLU-12          [-1, 256, 56, 56]               0\n",
            "           Conv2d-13          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-14          [-1, 256, 56, 56]               0\n",
            "           Conv2d-15          [-1, 256, 56, 56]         590,080\n",
            "             ReLU-16          [-1, 256, 56, 56]               0\n",
            "        MaxPool2d-17          [-1, 256, 28, 28]               0\n",
            "           Conv2d-18          [-1, 512, 28, 28]       1,180,160\n",
            "             ReLU-19          [-1, 512, 28, 28]               0\n",
            "           Conv2d-20          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-21          [-1, 512, 28, 28]               0\n",
            "           Conv2d-22          [-1, 512, 28, 28]       2,359,808\n",
            "             ReLU-23          [-1, 512, 28, 28]               0\n",
            "        MaxPool2d-24          [-1, 512, 14, 14]               0\n",
            "           Conv2d-25          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-26          [-1, 512, 14, 14]               0\n",
            "           Conv2d-27          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-28          [-1, 512, 14, 14]               0\n",
            "           Conv2d-29          [-1, 512, 14, 14]       2,359,808\n",
            "             ReLU-30          [-1, 512, 14, 14]               0\n",
            "        MaxPool2d-31            [-1, 512, 7, 7]               0\n",
            "AdaptiveAvgPool2d-32            [-1, 512, 7, 7]               0\n",
            "           Linear-33                 [-1, 4096]     102,764,544\n",
            "             ReLU-34                 [-1, 4096]               0\n",
            "          Dropout-35                 [-1, 4096]               0\n",
            "           Linear-36                 [-1, 4096]      16,781,312\n",
            "             ReLU-37                 [-1, 4096]               0\n",
            "          Dropout-38                 [-1, 4096]               0\n",
            "           Linear-39                   [-1, 10]          40,970\n",
            "================================================================\n",
            "Total params: 134,301,514\n",
            "Trainable params: 134,301,514\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 218.77\n",
            "Params size (MB): 512.32\n",
            "Estimated Total Size (MB): 731.67\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from torchvision import models\n",
        "model_import = models.vgg16(pretrained=False, num_classes=10).to(DEVICE)\n",
        "summary(model_import, (3, 224, 224))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_b5IsHnKUquV"
      },
      "outputs": [],
      "source": [
        "# Optimizer 설정\n",
        "optimizer = optim.Adam(model.parameters(), lr=LR)\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oy8oXE_mWARx",
        "outputId": "6a6c0c1d-7950-4f0c-bcd7-2b0c25f91777"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.302463\n"
          ]
        }
      ],
      "source": [
        "# Train 구현\n",
        "def train_one_epoch(model, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 200 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "# Evaluation 구현\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "            output = model(data)\n",
        "\n",
        "            # 배치 오차를 합산\n",
        "            test_loss += F.cross_entropy(output, target,\n",
        "                                         reduction='sum').item()\n",
        "\n",
        "            # 가장 높은 값을 가진 인덱스가 바로 예측값\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_one_epoch(model, train_loader, optimizer, epoch)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "\n",
        "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
        "          epoch, test_loss, test_accuracy))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JNxz2ARrE9Jp"
      },
      "source": [
        "## Excercise 1) RESNET18 모델 구현\n",
        "- [doc] (https://arxiv.org/pdf/1512.03385.pdf)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=1GgHATI5PFF8-PlBdGp9vDra2maRqLybl)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=1EYxIKJEI0rwIyW7ZZaFeZgJvol6Jb-XL)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=17DgT11woHwXACEGOfvkVd8pYmxRI7vQl)\n",
        "\n",
        "![image.png](http://drive.google.com/uc?id=12reHf9xtapZrVBG4LlNbNGa37ZeFfUqk)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_IJRFtgHw02"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets, utils\n",
        "from torchsummary import summary\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# DEVICE 설정\n",
        "USE_CUDA = torch.cuda.is_available()\n",
        "DEVICE = torch.device(\"cuda\" if USE_CUDA else \"cpu\")\n",
        "\n",
        "# Parameter 설정\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 64\n",
        "LR = 0.01\n",
        "\n",
        "# Transform 설정\n",
        "transform_CIFAR10 = transforms.Compose([\n",
        "    # transforms.Resize((224,224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225)),\n",
        "])\n",
        "\n",
        "# Dataset 설정\n",
        "train_dataset = datasets.CIFAR10(root = '../data',\n",
        "                                         train = True,\n",
        "                                         download = True,\n",
        "                                         transform = transform_CIFAR10)\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root = '../data',\n",
        "                                train = False,\n",
        "                                download = True,\n",
        "                                transform = transform_CIFAR10)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = BATCH_SIZE,\n",
        "                                           shuffle=True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1dykk5Om-cPG"
      },
      "outputs": [],
      "source": [
        "# Model 구현\n",
        "class Custom_RESNET(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Custom_RESNET, self).__init__()\n",
        "        self.maxpool2d = nn.MaxPool2d(kernel_size=3, stride=2)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "\n",
        "        self.conv1 = nn.Conv2d(in_channels=3, out_channels=64, kernel_size=7, stride=2, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(num_features=64)\n",
        "\n",
        "        self.conv2_1 = nn.Conv2d(64,64,3,padding=1)\n",
        "        self.conv2_2 = nn.Conv2d(64,64,3,padding=1)\n",
        "        self.conv2_3 = nn.Conv2d(64,64,3,padding=1)\n",
        "        self.conv2_4 = nn.Conv2d(64,64,3,padding=1)\n",
        "        self.bn2_1 = nn.BatchNorm2d(num_features=64)\n",
        "        self.bn2_2 = nn.BatchNorm2d(num_features=64)\n",
        "        self.bn2_3 = nn.BatchNorm2d(num_features=64)\n",
        "        self.bn2_4 = nn.BatchNorm2d(num_features=64)\n",
        "\n",
        "        self.conv3_1 = nn.Conv2d(64,128,3,padding=1, stride=2)\n",
        "        self.conv3_2 = nn.Conv2d(128,128,3,padding=1)\n",
        "        self.conv3_3 = nn.Conv2d(128,128,3,padding=1)\n",
        "        self.conv3_4 = nn.Conv2d(128,128,3,padding=1)\n",
        "        self.bn3_1 = nn.BatchNorm2d(num_features=128)\n",
        "        self.bn3_2 = nn.BatchNorm2d(num_features=128)\n",
        "        self.bn3_3 = nn.BatchNorm2d(num_features=128)\n",
        "        self.bn3_4 = nn.BatchNorm2d(num_features=128)\n",
        "\n",
        "        self.conv4_1 = nn.Conv2d(128,256,3,padding=1, stride=2)\n",
        "        self.conv4_2 = nn.Conv2d(256,256,3,padding=1)\n",
        "        self.conv4_3 = nn.Conv2d(256,256,3,padding=1)\n",
        "        self.conv4_4 = nn.Conv2d(256,256,3,padding=1)\n",
        "        self.bn4_1 = nn.BatchNorm2d(num_features=256)\n",
        "        self.bn4_2 = nn.BatchNorm2d(num_features=256)\n",
        "        self.bn4_3 = nn.BatchNorm2d(num_features=256)\n",
        "        self.bn4_4 = nn.BatchNorm2d(num_features=256)\n",
        "\n",
        "        self.conv5_1 = nn.Conv2d(256,512,3,padding=1, stride=2)\n",
        "        self.conv5_2 = nn.Conv2d(512,512,3,padding=1)\n",
        "        self.conv5_3 = nn.Conv2d(512,512,3,padding=1)\n",
        "        self.conv5_4 = nn.Conv2d(512,512,3,padding=1)\n",
        "        self.bn5_1 = nn.BatchNorm2d(num_features=512)\n",
        "        self.bn5_2 = nn.BatchNorm2d(num_features=512)\n",
        "        self.bn5_3 = nn.BatchNorm2d(num_features=512)\n",
        "        self.bn5_4 = nn.BatchNorm2d(num_features=512)\n",
        "\n",
        "        self.adaptiveavgpool2d = nn.AdaptiveAvgPool2d(1)\n",
        "\n",
        "        self.fc = nn.Linear(512, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        ########################################## Complete This Code~!\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        x1 = self.maxpool2d(x)\n",
        "\n",
        "        x2_1 = self.relu(self.bn2_1(self.conv2_1(x1)))\n",
        "        x2_2 = self.relu(self.bn2_2(self.conv2_2(x2_1))) + x1\n",
        "        x2_3 = self.relu(self.bn2_3(self.conv2_3(x2_2)))\n",
        "        x2_4 = self.relu(self.bn2_4(self.conv2_4(x2_3))) + x2_2\n",
        "\n",
        "        x3_1 = self.relu(self.bn3_1(self.conv3_1(x2_4)))\n",
        "        x3_2 = self.relu(self.bn3_2(self.conv3_2(x3_1))) #+ x2_4\n",
        "        x3_3 = self.relu(self.bn3_3(self.conv3_3(x3_2)))\n",
        "        x3_4 = self.relu(self.bn3_4(self.conv3_4(x3_3))) + x3_2\n",
        "\n",
        "        x4_1 = self.relu(self.bn4_1(self.conv4_1(x3_4)))\n",
        "        x4_2 = self.relu(self.bn4_2(self.conv4_2(x4_1))) #+ x3_4\n",
        "        x4_3 = self.relu(self.bn4_3(self.conv4_3(x4_2)))\n",
        "        x4_4 = self.relu(self.bn4_4(self.conv4_4(x4_3))) + x4_2\n",
        "\n",
        "        x5_1 = self.relu(self.bn5_1(self.conv5_1(x4_4)))\n",
        "        x5_2 = self.relu(self.bn5_2(self.conv5_2(x5_1))) #+ x4_4\n",
        "        x5_3 = self.relu(self.bn5_3(self.conv5_3(x5_2)))\n",
        "        x5_4 = self.relu(self.bn5_4(self.conv5_4(x5_3))) + x5_2\n",
        "\n",
        "        ########################################## Complete This Code~!\n",
        "\n",
        "        x = self.adaptiveavgpool2d(x5_4)\n",
        "        x = x.view(-1,512)\n",
        "        x = self.fc(x)\n",
        "        return x\n",
        "\n",
        "model = Custom_RESNET().to(DEVICE)\n",
        "summary(model, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YJq3fJZHHw7_"
      },
      "outputs": [],
      "source": [
        "from torchvision import models\n",
        "model_import = models.resnet18(pretrained=False, num_classes=10).to(DEVICE)\n",
        "summary(model_import, (3, 32, 32))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pUam0mfLavpg"
      },
      "outputs": [],
      "source": [
        "# Model, Optimizer 설정\n",
        "optimizer = optim.SGD(model.parameters(), lr=LR, momentum=0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GM0Tm7RJHzv-"
      },
      "outputs": [],
      "source": [
        "# Train 구현\n",
        "def train_one_epoch(model, train_loader, optimizer, epoch):\n",
        "    model.train()\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):\n",
        "        data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = F.cross_entropy(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % 200 == 0:\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "# Evaluation 구현\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    with torch.no_grad():\n",
        "        for data, target in test_loader:\n",
        "            data, target = data.to(DEVICE), target.to(DEVICE)\n",
        "            output = model(data)\n",
        "\n",
        "            # 배치 오차를 합산\n",
        "            test_loss += F.cross_entropy(output, target,\n",
        "                                         reduction='sum').item()\n",
        "\n",
        "            # 가장 높은 값을 가진 인덱스가 바로 예측값\n",
        "            pred = output.max(1, keepdim=True)[1]\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train_one_epoch(model, train_loader, optimizer, epoch)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "\n",
        "    print('[{}] Test Loss: {:.4f}, Accuracy: {:.2f}%'.format(\n",
        "          epoch, test_loss, test_accuracy))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
